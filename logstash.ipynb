{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e7398",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# --------------------------\n",
    "# STEP 1: Load and Preprocess Logs\n",
    "# --------------------------\n",
    "df = pd.read_csv(\"C:/Users/Vasu/Downloads/cleaned_proxy_logs - Copy.csv\")\n",
    "\n",
    "if 'timestamp' in df.columns:\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "else:\n",
    "    df['timestamp'] = pd.to_datetime(df['@timestamp'])\n",
    "\n",
    "df = df.rename(columns={\n",
    "    'src_ip': 'source_ip',\n",
    "    'domain': 'destination_domain'\n",
    "})\n",
    "\n",
    "df = df[['timestamp', 'source_ip', 'destination_domain', 'bytes_sent']]\n",
    "df.dropna(inplace=True)\n",
    "df['date'] = df['timestamp'].dt.floor('h')\n",
    "\n",
    "# --------------------------\n",
    "# STEP 2: Aggregate Traffic per IP\n",
    "# --------------------------\n",
    "traffic_df = df.groupby(['source_ip', 'date'])['bytes_sent'].sum().reset_index()\n",
    "traffic_df.rename(columns={'bytes_sent': 'total_bytes'}, inplace=True)\n",
    "\n",
    "# --------------------------\n",
    "# STEP 3: Load Malicious Domains List\n",
    "# --------------------------\n",
    "malicious_domain_path = 'C:/Users/swaya/OneDrive/Desktop/PROXY_Jan_to_May 2025_Malicious_Domain.txt'\n",
    "with open(malicious_domain_path, 'r') as f:\n",
    "    malicious_domains = set(line.strip().lower() for line in f.readlines())\n",
    "\n",
    "# --------------------------\n",
    "# STEP 4: LSTM Anomaly Detection\n",
    "# --------------------------\n",
    "def create_dataset(dataset, look_back=24):\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        X.append(dataset[i:i+look_back])\n",
    "        y.append(dataset[i+look_back])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def train_lstm_on_ip(ip_df):\n",
    "    ip_df = ip_df.set_index('date').resample('h').sum().fillna(0)\n",
    "    if len(ip_df) < 25:\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(ip_df[['total_bytes']])\n",
    "\n",
    "    look_back = 24\n",
    "    X, y = create_dataset(scaled_data, look_back)\n",
    "    if len(X) == 0:\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(look_back, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X, y, epochs=15, batch_size=8, verbose=0)\n",
    "\n",
    "    predicted = model.predict(X)\n",
    "    predicted = scaler.inverse_transform(predicted)\n",
    "    actual = scaler.inverse_transform(y.reshape(-1, 1))\n",
    "\n",
    "    residuals = np.abs(actual - predicted)\n",
    "    threshold = np.mean(residuals) + 1 * np.std(residuals)\n",
    "    anomalies = residuals > threshold\n",
    "    anomaly_indices = np.where(anomalies)[0]\n",
    "    anomaly_timestamps = ip_df.index[look_back:][anomaly_indices]\n",
    "\n",
    "    return anomalies.sum(), threshold, residuals, ip_df.reset_index(), anomaly_timestamps\n",
    "\n",
    "# --------------------------\n",
    "# STEP 5: Detect Suspicious IPs Based on Data Spike + Domain Check\n",
    "# --------------------------\n",
    "suspicious_summary = []\n",
    "all_ips = traffic_df['source_ip'].unique()\n",
    "\n",
    "print(\"\\n[+] Suspicious IPs (data spike + known malicious domain):\\n\")\n",
    "for ip in all_ips:\n",
    "    ip_df = traffic_df[traffic_df['source_ip'] == ip]\n",
    "    anomaly_count, threshold, residuals, full_series, anomaly_times = train_lstm_on_ip(ip_df)\n",
    "\n",
    "    if anomaly_count is None or anomaly_count == 0:\n",
    "        continue\n",
    "\n",
    "    # Domains accessed by IP during anomaly time\n",
    "    relevant_logs = df[(df['source_ip'] == ip) & (df['date'].isin(anomaly_times))]\n",
    "    contacted_domains = set(relevant_logs['destination_domain'].str.lower().unique())\n",
    "    matched_malicious = contacted_domains.intersection(malicious_domains)\n",
    "\n",
    "    if matched_malicious:\n",
    "        suspicious_summary.append({\n",
    "            \"IP\": ip,\n",
    "            \"Anomaly_Timestamps\": ', '.join(anomaly_times.astype(str)),\n",
    "            \"Matched_Domains\": ', '.join(matched_malicious),\n",
    "            \"Reason\": \"data spike + domain\"\n",
    "        })\n",
    "\n",
    "        print(f\"IP: {ip}\")\n",
    "        print(f\"  Anomaly Timestamps: {anomaly_times.tolist()}\")\n",
    "        print(f\"  Matched Malicious Domains: {list(matched_malicious)}\")\n",
    "        print(f\"  Reason: data spike + domain\\n\")\n",
    "\n",
    "# --------------------------\n",
    "# STEP 6: Export Final Report\n",
    "# --------------------------\n",
    "summary_df = pd.DataFrame(suspicious_summary)\n",
    "summary_df.to_csv(\"ips_report_filtered.csv\", index=False)\n",
    "print(\"\\n[+] Final report saved to 'suspicious_ips_report_filtered.csv'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
